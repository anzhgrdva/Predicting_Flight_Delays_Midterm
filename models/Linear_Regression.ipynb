{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.chdir('..')\n",
    "import supervised \n",
    "from supervised import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from extracted data\n",
    "df = pd.read_csv('data_for_modeling_final_2022-10-28_1227.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Take copy to measure data loss after clean-up\n",
    "# df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(columns=['mkt_carrier_fl_num', 'op_carrier_fl_num', 'origin_airport_id', 'dest_airport_id', 'dep_delay', 'month', 'fl_date_year',\n",
    "#     'fl_date_week_number', 'crs_dep_time', 'crs_arr_time', 'actual_elapsed_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mkt_carrier_fl_num', 'op_carrier_fl_num', 'origin_airport_id',\n",
       "       'dest_airport_id', 'dep_delay', 'arr_delay', 'crs_dep_time',\n",
       "       'crs_arr_time', 'crs_elapsed_time', 'actual_elapsed_time', 'air_time',\n",
       "       'distance', 'month', 'fl_date_year', 'fl_date_week_number',\n",
       "       'mean_dep_delay_carrier_origin_month',\n",
       "       'mean_arr_delay_carrier_origin_month',\n",
       "       'mean_dep_delay_carrier_origin_week',\n",
       "       'mean_arr_delay_carrier_origin_week',\n",
       "       'mean_dep_delay_carrier_origin_date',\n",
       "       'mean_arr_delay_carrier_origin_date',\n",
       "       'mean_dep_delay_carrier_origin_date_t-1_week',\n",
       "       'mean_arr_delay_carrier_origin_date_t-1_week',\n",
       "       'mean_dep_delay_carrier_origin_date_t-1_week_week_number',\n",
       "       'mean_arr_delay_carrier_origin_date_t-1_week_week_number',\n",
       "       'origin_region_Midwest', 'origin_region_Northeast',\n",
       "       'origin_region_South', 'origin_region_West', 'dest_region_Midwest',\n",
       "       'dest_region_Northeast', 'dest_region_South', 'dest_region_West',\n",
       "       'arr_hrs_ctg_Afternoon', 'arr_hrs_ctg_Evening', 'arr_hrs_ctg_Morning',\n",
       "       'arr_hrs_ctg_Night', 'dep_hrs_ctg_Afternoon', 'dep_hrs_ctg_Evening',\n",
       "       'dep_hrs_ctg_Morning', 'dep_hrs_ctg_Night', 'day_of_week_Friday',\n",
       "       'day_of_week_Monday', 'day_of_week_Saturday', 'day_of_week_Sunday',\n",
       "       'day_of_week_Thursday', 'day_of_week_Tuesday', 'day_of_week_Wednesday',\n",
       "       'haul_length_long', 'haul_length_medium', 'haul_length_short',\n",
       "       'cluster_km'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list with the columns to be scaled.\n",
    "# Create list with the columns to be scaled.\n",
    "numeric_cols = [\n",
    "\n",
    "# 'dep_delay', \n",
    "# 'arr_delay', <--- uncomment for testing model\n",
    "'year', 'distance', \n",
    "'month','crs_elapsed_time', \n",
    "'mean_payload_per_departure', 'mean_seats_per_departure', 'mean_passengers_per_departure', \n",
    "'mean_freight_per_departure', 'mean_mail_per_departure', 'mean_empty_seats_per_departure',\n",
    "\n",
    "'mean_dep_delay_carrier_origin_month', 'mean_arr_delay_carrier_origin_month', \n",
    "'mean_dep_delay_carrier_origin_week', 'mean_arr_delay_carrier_origin_week', \n",
    "'mean_dep_delay_carrier_origin_date', 'mean_arr_delay_carrier_origin_date', \n",
    "'mean_dep_delay_carrier_origin_date_t-1_week', 'mean_arr_delay_carrier_origin_date_t-1_week', \n",
    "'mean_dep_delay_carrier_origin_date_t-1_week_week_number', \n",
    "'mean_arr_delay_carrier_origin_date_t-1_week_week_number', \n",
    "'mean_dep_delay_carrier_origin_datet-1_year_week', \n",
    "'mean_arr_delay_carrier_origin_datet-1_year_week', \n",
    "'mean_dep_delay_carrier_origin_date_t-1_year_month', \n",
    "'mean_arr_delay_carrier_origin_date_t-1_year_month'\n",
    "]\n",
    "\n",
    "\n",
    "# Create a list with the dummy/categorical variables:\n",
    "cat_cols = [\n",
    "\n",
    "'origin_region_Midwest', 'origin_region_Northeast',\n",
    "'origin_region_South', 'origin_region_West', 'dest_region_Midwest',\n",
    "'dest_region_Northeast', 'dest_region_South', 'dest_region_West',\n",
    "\n",
    "'arr_hrs_ctg_Afternoon', 'arr_hrs_ctg_Evening', 'arr_hrs_ctg_Morning',\n",
    "'arr_hrs_ctg_Night', \n",
    "\n",
    "'dep_hrs_ctg_Afternoon', 'dep_hrs_ctg_Evening', 'dep_hrs_ctg_Morning', \n",
    "'dep_hrs_ctg_Night',\n",
    "\n",
    "'day_of_week_Friday', 'day_of_week_Monday', 'day_of_week_Saturday', \n",
    "'day_of_week_Sunday', 'day_of_week_Thursday', 'day_of_week_Tuesday', \n",
    "'day_of_week_Wednesday',\n",
    "\n",
    "'haul_length_long', 'haul_length_medium', 'haul_length_short'\n",
    "\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022-10-27 8:57 Here is the function to scale the data. Please read the function documentation. \n",
    "# This function has been saved to the midterm_functions.py file.\n",
    "def scale_data(df, numeric_cols, cat_cols):\n",
    "    \"\"\"\n",
    "    - Perform standardization (StandardScaler) on the numeric_cols of the dataframe. \n",
    "    - combines both numeric and categorical back to the entire feature dataframe.\n",
    "\n",
    "    Params:\n",
    "    - df: Dataframe object with both feature and target data. \n",
    "    - numeric_cols: Name of the numeric columns to be scaled.\n",
    "    - cat_cols: Name of the categorical columns (dummy variables) NOT to be scaled.\n",
    "\n",
    "    Returns: Dataframe with numeric data scaled and categorical data as-is.\n",
    "\n",
    "    \"\"\"\n",
    "    # Create the scaler based on the training dataset\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df[numeric_cols])\n",
    "    X_numeric_scaled = scaler.transform(df[numeric_cols])\n",
    "    X_categorical = df[cat_cols].to_numpy()\n",
    "    X = pd.DataFrame(np.hstack((X_categorical, X_numeric_scaled)), columns=cat_cols + numeric_cols)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function:\n",
    "df_scaled = scale_data(df, numeric_cols, cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['origin_region_Midwest', 'origin_region_Northeast',\n",
       "       'origin_region_South', 'origin_region_West', 'dest_region_Midwest',\n",
       "       'dest_region_Northeast', 'dest_region_South', 'dest_region_West',\n",
       "       'arr_hrs_ctg_Afternoon', 'arr_hrs_ctg_Evening', 'arr_hrs_ctg_Morning',\n",
       "       'arr_hrs_ctg_Night', 'dep_hrs_ctg_Afternoon', 'dep_hrs_ctg_Evening',\n",
       "       'dep_hrs_ctg_Morning', 'dep_hrs_ctg_Night', 'day_of_week_Friday',\n",
       "       'day_of_week_Monday', 'day_of_week_Saturday', 'day_of_week_Sunday',\n",
       "       'day_of_week_Thursday', 'day_of_week_Tuesday', 'day_of_week_Wednesday',\n",
       "       'haul_length_long', 'haul_length_medium', 'haul_length_short',\n",
       "       'arr_delay', 'year_x', 'distance_x', 'month', 'crs_elapsed_time',\n",
       "       'mean_payload_per_departure', 'mean_seats_per_departure',\n",
       "       'mean_passengers_per_departure', 'mean_freight_per_departure',\n",
       "       'mean_mail_per_departure', 'mean_empty_seats_per_departure',\n",
       "       'mean_dep_delay_carrier_origin_month',\n",
       "       'mean_arr_delay_carrier_origin_month',\n",
       "       'mean_dep_delay_carrier_origin_week',\n",
       "       'mean_arr_delay_carrier_origin_week',\n",
       "       'mean_dep_delay_carrier_origin_date',\n",
       "       'mean_arr_delay_carrier_origin_date',\n",
       "       'mean_dep_delay_carrier_origin_date_t-1_week',\n",
       "       'mean_arr_delay_carrier_origin_date_t-1_week',\n",
       "       'mean_dep_delay_carrier_origin_date_t-1_week_week_number',\n",
       "       'mean_arr_delay_carrier_origin_date_t-1_week_week_number',\n",
       "       'mean_dep_delay_carrier_origin_datet-1_year_week',\n",
       "       'mean_arr_delay_carrier_origin_datet-1_year_week',\n",
       "       'mean_dep_delay_carrier_origin_date_t-1_year_month',\n",
       "       'mean_arr_delay_carrier_origin_date_t-1_year_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.95933052e+08  3.95933052e+08  3.95933052e+08  3.95933052e+08\n",
      "  6.21945124e+08  6.21945124e+08  6.21945124e+08  6.21945124e+08\n",
      " -5.60673923e+08 -5.60673923e+08 -5.60673923e+08 -5.60673923e+08\n",
      " -2.57546243e+08 -2.57546243e+08 -2.57546243e+08 -2.57546243e+08\n",
      " -8.38632083e+08 -8.38632083e+08 -8.38632083e+08 -8.38632083e+08\n",
      " -8.38632083e+08 -8.38632083e+08 -8.38632083e+08 -1.88997986e+09\n",
      " -1.88997986e+09 -1.88997986e+09 -1.39290273e+08  3.36962349e-01\n",
      " -1.93944859e-02 -4.65748107e-01  1.12200713e-02  1.82339613e+09\n",
      " -2.00634724e+09  2.46130863e-03 -3.90485307e-03 -1.54957909e+09\n",
      " -1.35129485e+10 -3.45586076e+10  2.31825100e+09  5.88171311e+09\n",
      "  2.31825100e+09  5.88171311e+09  1.97326682e+09  5.76529329e+09\n",
      "  2.18713629e+09  6.02320313e+09  2.27845914e+09  5.23997290e+09\n",
      "  2.43758423e+09  5.76671201e+09]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.037055738549542805"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_scaled.drop('arr_delay', axis = 1)   # features\n",
    "y = df_scaled['arr_delay']    # labels\n",
    "\n",
    "# Initialize the object \n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fit the model on our data\n",
    "lr.fit(X, y)\n",
    "\n",
    "\n",
    "print(lr.coef_)\n",
    "lr.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Data has been scaled.**\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 2 is smaller than n_iter=10. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1901, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1901, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1901, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1901, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1901, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1901, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1901, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1901, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1901, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1901, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1544, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 1348, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/metrics/_classification.py\", line 104, in _check_targets\n",
      "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
      "ValueError: continuous is not supported\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan]\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Liner_Regression evaluation metrics: \n",
      "\tTest data\tTraining data\t\tDifference\n",
      "RMSE: \t\t0.98\t\t0.96\t\t0.02\n",
      "MAE: \t\t0.71\t\t0.71\t\t-0.00\n",
      "R^2: \t\t0.04\t\t0.04\t\t0.00\n",
      "Best model parameters from randomized search: {'normalize': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "par = {\n",
    "    'normalize': [True, False]\n",
    "}\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr_attributes = supervised(X, y, lr, par, 'Liner_Regression')\n",
    "best_lr = lr_attributes.get_best_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.34961482e+08,  1.30110097e+08,  1.83538429e+08,  1.75524537e+08,\n",
       "        5.91631724e+07,  5.53728704e+07,  7.66175720e+07,  7.46155448e+07,\n",
       "       -4.03470391e+08, -4.80353814e+08, -4.58449301e+08, -2.70309478e+08,\n",
       "        1.36007906e+07,  1.57533871e+07,  1.64713357e+07,  4.27388451e+06,\n",
       "        9.28990966e+08,  9.25878000e+08,  8.74329254e+08,  9.13320359e+08,\n",
       "        9.21324494e+08,  9.17620689e+08,  9.14039310e+08, -4.12440034e+05,\n",
       "       -2.08422097e+06, -2.10938442e+06,  4.23078446e+14,  3.37296196e-01,\n",
       "       -1.92325417e-02, -4.66237462e-01,  1.01788594e-02,  1.55172677e+10,\n",
       "       -1.70761178e+10,  3.23001520e-03, -3.81886768e-03, -1.31811008e+10,\n",
       "        1.32045033e+11,  5.28500162e+11,  1.57361520e+11, -1.51541461e+11,\n",
       "        1.57361520e+11, -1.51541461e+11,  8.00894962e+10, -1.00380322e+11,\n",
       "       -5.45089730e+11,  3.37140551e+11, -1.95902785e+10, -4.27637075e+10,\n",
       "        3.78224378e+10, -4.19413761e+11])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear_Regression_v2_2022-10-28_1313.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the file to CSV\n",
    "from datetime import datetime\n",
    "datetime_now = datetime.now().strftime('%Y-%m-%d_%H%M')\n",
    "filename = f'Linear_Regression_v2_{datetime_now}.pkl'\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "pickle.dump(df,open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_prepared_2022-10-28_1345.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function:\n",
    "df_test_scaled = scale_data(df_test, numeric_cols, cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Open the model and predict\n",
    "# pickled_model = pickle.load(open('Linear_Regression_v2_2022-10-28_1313.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LinearRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/ava_mac/Documents/Coding/LHL/W6/Predicting_Flight_Delays_Midterm/models/Linear_Regression.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ava_mac/Documents/Coding/LHL/W6/Predicting_Flight_Delays_Midterm/models/Linear_Regression.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mtest_prepared_2022-10-28_1131.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ava_mac/Documents/Coding/LHL/W6/Predicting_Flight_Delays_Midterm/models/Linear_Regression.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m predictions \u001b[39m=\u001b[39m lr\u001b[39m.\u001b[39;49mpredict(df_test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ava_mac/Documents/Coding/LHL/W6/Predicting_Flight_Delays_Midterm/models/Linear_Regression.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(predictions)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:362\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    349\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[39m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decision_function(X)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/linear_model/_base.py:343\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decision_function\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m--> 343\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    345\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(X, accept_sparse\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcoo\u001b[39m\u001b[39m\"\u001b[39m], reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    346\u001b[0m     \u001b[39mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/new_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1222\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1217\u001b[0m     fitted \u001b[39m=\u001b[39m [\n\u001b[1;32m   1218\u001b[0m         v \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m \u001b[39mvars\u001b[39m(estimator) \u001b[39mif\u001b[39;00m v\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m v\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1219\u001b[0m     ]\n\u001b[1;32m   1221\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fitted:\n\u001b[0;32m-> 1222\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This LinearRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('test_prepared_2022-10-28_1131.csv')\n",
    "predictions = lr.predict(df_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('new_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c229a7bb837f7622ff6522438b225aa15e7a80f2ac0a1c0d5851fa7ebe2f25d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
